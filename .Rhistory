library(rTLS)
4*4
16*4
64*4
100/256
64*4
256*4
100/1024
1024*4
100/4096
4096*4
100/16384
10*16384
10/16384
library(rTLS)
data("pc_tree")
data <- pc_tree
data("pc_tree")
#' @author J. Antonio Guzman Q. and Ronny Hernandez
#' @references Greaves, H. E., Vierling, L. A., Eitel, J. U., Boelman, N. T., Magney, T. S., Prager, C. M., & Griffin, K. L. (2015). Estimating aboveground biomass and leaf area of low-stature Arctic shrubs with terrestrial LiDAR. Remote Sensing of Environment, 164, 26-35.
#'
#' @examples
#' data("pc_tree")
#'
#' ###Create voxels of a size of 0.5.
#' voxels(pc_tree, voxel.size = 0.5)
#'
#'@export
voxels <- function(cloud, voxel.size) {
xi <- round(min(cloud[,1]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,1])) - 1))    ##  Buffer the minimum point value by half the voxel size to find the lower bound for the x,y, and z voxels
yi <- round(min(cloud[,2]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,2])) - 1))
zi <- round(min(cloud[,3]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,3])) - 1))
cloud$x_vox <- ceiling((cloud[,1]-xi)/voxel.size)    ##  Assign x, y, and z "voxel coordinates" to each point as a point attribute
cloud$y_vox <- ceiling((cloud[,2]-yi)/voxel.size)
cloud$z_vox <- ceiling((cloud[,3]-zi)/voxel.size)
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
voxels.cloud <- as.data.frame(voxels.cloud)
xc <- (min(cloud[,1]) - voxel.size/2) + (voxels.cloud$x_vox*voxel.size)
yc <- (min(cloud[,2]) - voxel.size/2) + (voxels.cloud$y_vox*voxel.size)
zc <- (min(cloud[,3]) - voxel.size/2) + (voxels.cloud$z_vox*voxel.size)
voxels.cloud$x_vox <- round(xc, max(nchar(sub('.','', cloud[,1])) - 1))
voxels.cloud$y_vox <- round(yc, max(nchar(sub('.','', cloud[,2])) - 1))
voxels.cloud$z_vox <- round(zc, max(nchar(sub('.','', cloud[,3])) - 1))
return(voxels.cloud)
}
voxels(pc_tree, voxel.size = 0.5)
library(bio3d)
library(nabor)
library(dplyr)
library(plyr)
library(foreach)
library(doParallel)
library(boot)
library(rgl)
#' @author J. Antonio Guzman Q. and Ronny Hernandez
#' @references Greaves, H. E., Vierling, L. A., Eitel, J. U., Boelman, N. T., Magney, T. S., Prager, C. M., & Griffin, K. L. (2015). Estimating aboveground biomass and leaf area of low-stature Arctic shrubs with terrestrial LiDAR. Remote Sensing of Environment, 164, 26-35.
#'
#' @examples
#' data("pc_tree")
#'
#' ###Create voxels of a size of 0.5.
#' voxels(pc_tree, voxel.size = 0.5)
#'
#'@export
voxels <- function(cloud, voxel.size) {
xi <- round(min(cloud[,1]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,1])) - 1))    ##  Buffer the minimum point value by half the voxel size to find the lower bound for the x,y, and z voxels
yi <- round(min(cloud[,2]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,2])) - 1))
zi <- round(min(cloud[,3]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,3])) - 1))
cloud$x_vox <- ceiling((cloud[,1]-xi)/voxel.size)    ##  Assign x, y, and z "voxel coordinates" to each point as a point attribute
cloud$y_vox <- ceiling((cloud[,2]-yi)/voxel.size)
cloud$z_vox <- ceiling((cloud[,3]-zi)/voxel.size)
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
voxels.cloud <- as.data.frame(voxels.cloud)
xc <- (min(cloud[,1]) - voxel.size/2) + (voxels.cloud$x_vox*voxel.size)
yc <- (min(cloud[,2]) - voxel.size/2) + (voxels.cloud$y_vox*voxel.size)
zc <- (min(cloud[,3]) - voxel.size/2) + (voxels.cloud$z_vox*voxel.size)
voxels.cloud$x_vox <- round(xc, max(nchar(sub('.','', cloud[,1])) - 1))
voxels.cloud$y_vox <- round(yc, max(nchar(sub('.','', cloud[,2])) - 1))
voxels.cloud$z_vox <- round(zc, max(nchar(sub('.','', cloud[,3])) - 1))
return(voxels.cloud)
}
voxels(pc_tree, voxel.size = 0.5)
xi <- round(min(cloud[,1]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,1])) - 1))    ##  Buffer the minimum point value by half the voxel size to find the lower bound for the x,y, and z voxels
cloud <- pc_tree
xi <- round(min(cloud[,1]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,1])) - 1))    ##  Buffer the minimum point value by half the voxel size to find the lower bound for the x,y, and z voxels
yi <- round(min(cloud[,2]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,2])) - 1))
voxel.size = 0.5
xi <- round(min(cloud[,1]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,1])) - 1))    ##  Buffer the minimum point value by half the voxel size to find the lower bound for the x,y, and z voxels
yi <- round(min(cloud[,2]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,2])) - 1))
zi <- round(min(cloud[,3]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,3])) - 1))
cloud$x_vox <- ceiling((cloud[,1]-xi)/voxel.size)    ##  Assign x, y, and z "voxel coordinates" to each point as a point attribute
cloud$y_vox <- ceiling((cloud[,2]-yi)/voxel.size)
cloud$z_vox <- ceiling((cloud[,3]-zi)/voxel.size)
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
cloud$x_vox <- ceiling((cloud[,1]-xi)/voxel.size)    ##  Assign x, y, and z "voxel coordinates" to each point as a point attribute
cloud$y_vox <- ceiling((cloud[,2]-yi)/voxel.size)
cloud$z_vox <- ceiling((cloud[,3]-zi)/voxel.size)
cloud$z_vox
cloud$y_vox
cloud$x_vox
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE)
cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE)
library("dplyr", lib.loc="~/R/win-library/3.5")
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE)
cloud$z_vox
max(nchar(sub('.','', cloud[,3])) - 1)
max(nchar(sub('.','', cloud[,2])) - 1)
max(nchar(sub('.','', cloud[,1])) - 1)
xi <- round(min(cloud[,1]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,1])) - 1))    ##  Buffer the minimum point value by half the voxel size to find the lower bound for the x,y, and z voxels
yi <- round(min(cloud[,2]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,2])) - 1))
zi <- round(min(cloud[,3]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,3])) - 1))
cloud$x_vox <- ceiling((cloud[,1]-xi)/voxel.size)    ##  Assign x, y, and z "voxel coordinates" to each point as a point attribute
cloud$y_vox <- ceiling((cloud[,2]-yi)/voxel.size)
cloud$z_vox <- ceiling((cloud[,3]-zi)/voxel.size)
cloud
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
cloud %>% count(x_vox, y_vox, z_vox)
cloud %>% count(x_vox, y_vox, z_vox)
library(bio3d)
library(nabor)
library(plyr)
library(dplyr)
library(foreach)
library(doParallel)
library(boot)
library(rgl)
data("pc_tree")
#' @author J. Antonio Guzman Q. and Ronny Hernandez
#' @references Greaves, H. E., Vierling, L. A., Eitel, J. U., Boelman, N. T., Magney, T. S., Prager, C. M., & Griffin, K. L. (2015). Estimating aboveground biomass and leaf area of low-stature Arctic shrubs with terrestrial LiDAR. Remote Sensing of Environment, 164, 26-35.
#'
#' @examples
#' data("pc_tree")
#'
#' ###Create voxels of a size of 0.5.
#' voxels(pc_tree, voxel.size = 0.5)
#'
#'@export
voxels <- function(cloud, voxel.size) {
xi <- round(min(cloud[,1]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,1])) - 1))    ##  Buffer the minimum point value by half the voxel size to find the lower bound for the x,y, and z voxels
yi <- round(min(cloud[,2]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,2])) - 1))
zi <- round(min(cloud[,3]) - voxel.size/2, digits = max(nchar(sub('.','', cloud[,3])) - 1))
cloud$x_vox <- ceiling((cloud[,1]-xi)/voxel.size)    ##  Assign x, y, and z "voxel coordinates" to each point as a point attribute
cloud$y_vox <- ceiling((cloud[,2]-yi)/voxel.size)
cloud$z_vox <- ceiling((cloud[,3]-zi)/voxel.size)
voxels.cloud <- cloud %>% count(x_vox, y_vox, z_vox, sort = TRUE) #Cound the number of points per voxel
voxels.cloud <- as.data.frame(voxels.cloud)
xc <- (min(cloud[,1]) - voxel.size/2) + (voxels.cloud$x_vox*voxel.size)
yc <- (min(cloud[,2]) - voxel.size/2) + (voxels.cloud$y_vox*voxel.size)
zc <- (min(cloud[,3]) - voxel.size/2) + (voxels.cloud$z_vox*voxel.size)
voxels.cloud$x_vox <- round(xc, max(nchar(sub('.','', cloud[,1])) - 1))
voxels.cloud$y_vox <- round(yc, max(nchar(sub('.','', cloud[,2])) - 1))
voxels.cloud$z_vox <- round(zc, max(nchar(sub('.','', cloud[,3])) - 1))
return(voxels.cloud)
}
voxels(pc_tree, voxel.size = 0.5)
vo <- voxels(pc_tree, voxel.size = 0.5)
class(vo)
head(vo)
vo
data <- vo
length(vox$n)
length(data$n)
voxel.size
mean(data$n/(voxel.size[i]^3))
mean(data$n/(voxel.size^3))
var(data$n/(voxel.size^3))
sd(data$n/(voxel.size^3))
shannon(vox$n)
shannon <- function(n_points) {
p.i <- n_points/sum(n_points)
H <- (-1) * sum(p.i * log(p.i))
return(H)
}
shannon_boot <- function(n_points, i) {
n_boot <- n_points[i]
p.i <- n_boot/sum(n_boot)
H <- (-1) * sum(p.i * log(p.i))
return(H)
}
shannon <- function(n_points) {
p.i <- n_points/sum(n_points)
H <- (-1) * sum(p.i * log(p.i))
return(H)
}
shannon(data$n)
vox$eq <- 1
data$eq <- 1
H <- shannon(data$n) #H index
data$eq <- 1
Hmax <- shannon(data$eq) #H max
Hmax
H
R = 100
boot(data$n, shannon_boot, R= R)$t
boot(data$n, shannon_boot, R= R)$t
boot(data$n, shannon_boot, R= R)$t
H_boot_mean <- mean(h_boot) #H index with boot
h_boot <- boot(data$n, shannon_boot, R= R)$t
H_boot_mean <- mean(h_boot) #H index with boot
H_boot_sd <- sd(h_boot)
H_boot_mean
H_boot_sd
Voxel.size <- voxel.size
frame <- data.frame(Voxel.size)
frame
frame <- data.frame(Voxel.size, Count)
Voxel.size <- voxel.size
Count <- length(data$n) #Number de voxels
Density_mean <- mean(data$n/(voxel.size^3)) #Mean density of points
Density_sd <- sd(data$n/(voxel.size^3)) #Sd of the density of points
H <- shannon(data$n) #H index
data$eq <- 1
Hmax <- shannon(data$eq) #H max
Equitavility <- H/Hmax #Equitavility
Negentropy <- Hmax - H #Negentropy
frame <- data.frame(Voxel.size, Count)
frame
names(frame)
H <- shannon(data$n) #H index
frame <- data.frame(Voxel.size, Count, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy)
names(frame)
frame
Negentropy_boot
h_boot <- boot(data$n, shannon_boot, R= R)$t
H_boot_mean <- mean(h_boot) #H index with boot
H_boot_sd <- sd(h_boot)
Equitavility_boot <- H_boot_mean/Hmax #Equitavility based on boot
Negentropy_boot <- Hmax - H_boot_mean #Negentropy based on boot
Equitavility_boot
Negentropy_boot
frame <- data.frame(Voxel.size, Count, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy, H_boot_mean, H_boot_sd, Equitavility_boot, Negentropy_boot)
names(frame)
shannon <- function(n_points) {
p.i <- n_points/sum(n_points)
H <- (-1) * sum(p.i * log(p.i))
return(H)
}
shannon_boot <- function(n_points, i) {
n_boot <- n_points[i]
p.i <- n_boot/sum(n_boot)
H <- (-1) * sum(p.i * log(p.i))
return(H)
}
#' @author J. Antonio Guzman Q. and Ronny Hernandez
#'
#' @examples
#' data("pc_tree")
#'
#' ###Create voxels of a size of 0.5.
#' vox <- voxels(pc_tree, voxel.size = 0.5)
#' summary_voxels(vox)
#'
#'@export
summary_voxels <- function(data, voxel.size, bootstrap, R) {
Voxel.size <- voxel.size
Count <- length(data$n) #Number de voxels
Density_mean <- mean(data$n/(voxel.size^3)) #Mean density of points
Density_sd <- sd(data$n/(voxel.size^3)) #Sd of the density of points
H <- shannon(data$n) #H index
data$eq <- 1
Hmax <- shannon(data$eq) #H max
Equitavility <- H/Hmax #Equitavility
Negentropy <- Hmax - H #Negentropy
if(bootstrap == FALSE ) {
frame <- data.frame(Voxel.size, Count, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy)
} else if(bootstrap == TRUE) {
h_boot <- boot(data$n, shannon_boot, R= R)$t
H_boot_mean <- mean(h_boot) #H index with boot
H_boot_sd <- sd(h_boot)
Equitavility_boot <- H_boot_mean/Hmax #Equitavility based on boot
Negentropy_boot <- Hmax - H_boot_mean #Negentropy based on boot
frame <- data.frame(Voxel.size, Count, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy, H_boot_mean, H_boot_sd, Equitavility_boot, Negentropy_boot)
}
return(frame)
}
summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 100)
data("pc_tree")
vox <- voxels(pc_tree, voxel.size = 0.5)
vox
vox
summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE)
#' ###Create voxels of a size of 0.5.
#' vox <- voxels(pc_tree, voxel.size = 0.5)
#'
#' ###Summary voxels
#' summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE)
#'
#' ###Summary voxels and estimated the entropy using bootstrap with 100 replicates
#' summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 100)
#'
#'@export
summary_voxels <- function(data, voxel.size, bootstrap, R) {
Voxel.size <- voxel.size
N_voxels <- length(data$n) #Number de voxels
Density_mean <- mean(data$n/(voxel.size^3)) #Mean density of points
Density_sd <- sd(data$n/(voxel.size^3)) #Sd of the density of points
H <- shannon(data$n) #H index
data$eq <- 1
Hmax <- shannon(data$eq) #H max
Equitavility <- H/Hmax #Equitavility
Negentropy <- Hmax - H #Negentropy
if(bootstrap == FALSE ) {
frame <- data.frame(Voxel.size, N_voxels, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy)
} else if(bootstrap == TRUE) {
h_boot <- boot(data$n, shannon_boot, R= R)$t
H_boot_mean <- mean(h_boot) #H index with boot
H_boot_sd <- sd(h_boot)
Equitavility_boot <- H_boot_mean/Hmax #Equitavility based on boot
Negentropy_boot <- Hmax - H_boot_mean #Negentropy based on boot
frame <- data.frame(Voxel.size, N_voxels, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy, H_boot_mean, H_boot_sd, Equitavility_boot, Negentropy_boot)
}
return(frame)
}
summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 100)
summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 1000)
summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 1000)
library(rTLS)
data("pc_tree")
vox <- voxels(pc_tree, voxel.size = 0.5)
summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE)
#' ###Create voxels of a size of 0.5.
#' vox <- voxels(pc_tree, voxel.size = 0.5)
#'
#' ###Summary voxels
#' summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE)
#'
#' ###Summary voxels and estimated the entropy using bootstrap with 1000 replicates
#' summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 1000)
#'
#'@export
summary_voxels <- function(data, voxel.size, bootstrap, R) {
Voxel.size <- voxel.size
N_voxels <- length(data$n) #Number de voxels
Volumen <- (voxel.size^3)*N_voxels
Density_mean <- mean(data$n/(voxel.size^3)) #Mean density of points
Density_sd <- sd(data$n/(voxel.size^3)) #Sd of the density of points
H <- shannon(data$n) #H index
data$eq <- 1
Hmax <- shannon(data$eq) #H max
Equitavility <- H/Hmax #Equitavility
Negentropy <- Hmax - H #Negentropy
if(bootstrap == FALSE ) {
frame <- data.frame(Voxel.size, N_voxels, Volumen, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy)
} else if(bootstrap == TRUE) {
h_boot <- boot(data$n, shannon_boot, R= R)$t
H_boot_mean <- mean(h_boot) #H index with boot
H_boot_sd <- sd(h_boot)
Equitavility_boot <- H_boot_mean/Hmax #Equitavility based on boot
Negentropy_boot <- Hmax - H_boot_mean #Negentropy based on boot
frame <- data.frame(Voxel.size, N_voxels, Volumen, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy, H_boot_mean, H_boot_sd, Equitavility_boot, Negentropy_boot)
}
return(frame)
}
summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE)
shannon <- function(n_points) {
p.i <- n_points/sum(n_points)
H <- (-1) * sum(p.i * log(p.i))
return(H)
}
shannon_boot <- function(n_points, i) {
n_boot <- n_points[i]
p.i <- n_boot/sum(n_boot)
H <- (-1) * sum(p.i * log(p.i))
return(H)
}
vox <- voxels(pc_tree, voxel.size = 0.5)
summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE)
names(summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE))
library(rTLS)
detach("package:rTLS", unload=TRUE)
library("rTLS", lib.loc="~/R/win-library/3.5")
summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 1000)
names(summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 1000))
library(rTLS)
0.5*0.5*0.5
0.125*697
