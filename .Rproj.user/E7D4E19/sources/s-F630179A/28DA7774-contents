#' @import dplyr
#'
#' @title Voxels summary
#'
#' @description Create a summary of the voxels created using the function \code{voxels}.
#'
#' @param data A \code{data.frame} with xyz coordinates of the voxels in the first three columns and a fourth column with the number of points in each voxel.
#' @param voxel.size A positive \code{numeric} vector indicating the size used in \code{voxels}. It is needed to estimated metrics of density.1
#' @param bootstrap A logical vector length 1 vector. If \code{bootstrap = TRUE}, it compute a bootstrap on the H index calculations.
#' @param R A positive \code{integer} of length 1 indicating the number of bootstrap replicates.
#' @return A \code{data.frame} with with the summary of \code{data}.
#' @details The function estimate 9 main statistics of the voxels. Specifically, the first three columns (ei. \code(Voxel.size), \code(N_voxels), \code(Volumen)) describe the size of the voxel used, the number of voxels created, and the total volumen they represent.
#' Following columns represent the mean (\code{Density_mean}) and sd (\code{Density_sd}) of the density of points per voxel. Columns 6:10 provide metrics calculated using the Shannon index. Specifically, \code{H} describe the entropy, \code{H_max} the maximun entropy, \code{Equitavility} the ratio between \code{H} and \code{Hmax}, and \code{Negentropy} describe the product of \code{Hmax} - \code{H}.
#' If \code{bootstrap = TRUE} four more columns are created (10:13). These represent the mean and sd of the H index estimated using bootstrap (\code{H_boot_mean} and \code{H_boot_sd}), the \code{Equtavility_boot} as the ratio of the ratio between \code{H_boot_sd} and \code{Hmax}, and \code{Negentropy_boot} as the product \code{Hmax} - \code{H_boot_mean}.
#'
#' @author J. Antonio Guzman Q. and Ronny Hernandez
#'
#' @examples
#' data("pc_tree")
#'
#' ###Create voxels of a size of 0.5.
#' vox <- voxels(pc_tree, voxel.size = 0.5)
#'
#' ###Summary voxels
#' summary_voxels(vox, voxel.size = 0.5, bootstrap = FALSE)
#'
#' ###Summary voxels and estimated the entropy using bootstrap with 1000 replicates
#' summary_voxels(vox, voxel.size = 0.5, bootstrap = TRUE, R = 1000)
#'
#'@export
summary_voxels <- function(data, voxel.size, bootstrap, R) {
  
  Voxel.size <- voxel.size
  N_voxels <- length(data$n) #Number de voxels
  Volumen <- (voxel.size^3)*N_voxels
  Density_mean <- mean(data$n/(voxel.size^3)) #Mean density of points
  Density_sd <- sd(data$n/(voxel.size^3)) #Sd of the density of points
  H <- shannon(data$n) #H index
  data$eq <- 1
  Hmax <- shannon(data$eq) #H max
  Equitavility <- H/Hmax #Equitavility
  Negentropy <- Hmax - H #Negentropy
  
  if(bootstrap == FALSE ) {
    frame <- data.frame(Voxel.size, N_voxels, Volumen, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy)
    
  } else if(bootstrap == TRUE) {
    h_boot <- boot(data$n, shannon_boot, R= R)$t
    H_boot_mean <- mean(h_boot) #H index with boot
    H_boot_sd <- sd(h_boot)
    Equitavility_boot <- H_boot_mean/Hmax #Equitavility based on boot
    Negentropy_boot <- Hmax - H_boot_mean #Negentropy based on boot
    
    frame <- data.frame(Voxel.size, N_voxels, Volumen, Density_mean, Density_sd, H, Hmax, Equitavility, Negentropy, H_boot_mean, H_boot_sd, Equitavility_boot, Negentropy_boot)
  }
  return(frame)
}

shannon <- function(n_points) {
  p.i <- n_points/sum(n_points)
  H <- (-1) * sum(p.i * log(p.i))
  return(H)
}

shannon_boot <- function(n_points, i) {
  n_boot <- n_points[i]
  p.i <- n_boot/sum(n_boot)
  H <- (-1) * sum(p.i * log(p.i))
  return(H)
}
